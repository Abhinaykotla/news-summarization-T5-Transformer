{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naRIe7GDs_8n"
   },
   "source": [
    "# Fine Tuning Transformer for Summary Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Mflqoks_8s"
   },
   "source": [
    "Fine-tuning a transformer model for the **summarization task**. The objective is to train the model to generate concise summaries of articles or documents. Summarization can be achieved in two main ways:\n",
    "\n",
    "1. **Extractive Summarization**: The model identifies and assembles the key sentences from the article to form a summary, essentially \"extracting\" existing content without altering it.\n",
    "   \n",
    "2. **Abstractive Summarization**: This approach enables the model to create new sentences that encapsulate the core ideas of the article, resulting in a summary that may include information rephrased or condensed rather than simply copied from the article.\n",
    "\n",
    "The workflow includes:\n",
    "\n",
    "1. **Setting Up the Environment**: Installing and importing the necessary libraries.\n",
    "   \n",
    "2. **Preparing the Dataset**: Creating a custom class to handle data processing.\n",
    "   \n",
    "3. **Model Fine-Tuning**: Writing functions to fine-tune the transformer model.\n",
    "   \n",
    "4. **Model Validation**: Evaluating the model’s performance after training.\n",
    "   \n",
    "5. **Main Workflow**:\n",
    "    - Importing and preprocessing the dataset\n",
    "    - Creating a dataset and dataloader\n",
    "    - Defining the neural network and optimizer\n",
    "    - Training the model\n",
    "    - Validating the model and generating summaries\n",
    "\n",
    "6. **Reviewing Summaries**: Analyzing some example summaries generated by the model.\n",
    "\n",
    "### Technical Details\n",
    "\n",
    "- **Dataset**: \n",
    "  Using the *News Summary* dataset from [Kaggle](https://www.kaggle.com/sunnysai12345/news-summary), which consists of news summaries from Indian newspapers. Focusing on `news_summary.csv`, which contains 4,514 entries with fields like author, publication date, headline, URL, a brief summary, and the full article text.\n",
    "\n",
    "- **Model**: \n",
    "  Utilizing **T5**, a powerful transformer model designed for various NLP tasks. T5 frames each task as a \"text-to-text\" problem, where both input and output are treated as text, allowing it to work seamlessly across diverse NLP applications. Following guidance from the T5 research paper to ensure that the data aligns with the model’s requirements. [T5 paper](https://arxiv.org/abs/1910.10683) and [Hugging Face T5 documentation](https://huggingface.co/transformers/model_doc/t5.html) provide further technical insights.\n",
    "\n",
    "- **Hardware and Libraries**: \n",
    "  Using Python 3.6+, PyTorch, and the Transformers library. Since the model is resource-intensive, operating with a GPU-enabled setup.\n",
    "\n",
    "- **Objective**: \n",
    "  To fine-tune T5 to generate summaries that closely match or surpass the quality of actual article summaries, capturing essential points without losing critical information.\n",
    "\n",
    "The project is set to explore how effectively T5 can be fine-tuned for summarization, aiming for high-quality summaries that retain the article's core information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPyqAf8es_8x"
   },
   "source": [
    "<a id='section01'></a>\n",
    "### Preparing Environment and Importing Libraries\n",
    "\n",
    "Installing the necessary libraries followed by importing the libraries and modules needed to run our script. \n",
    "Will be installing:\n",
    "* transformers\n",
    "\n",
    "Libraries imported are:\n",
    "* Pandas\n",
    "* Pytorch\n",
    "* Pytorch Utils for Dataset and Dataloader\n",
    "* Transformers\n",
    "* T5 Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "executionInfo": {
     "elapsed": 27041,
     "status": "ok",
     "timestamp": 1651511788114,
     "user": {
      "displayName": "Chaithra K.C",
      "userId": "06590399226295405413"
     },
     "user_tz": 240
    },
    "id": "WD_vnyLXZQzD",
    "outputId": "00977bfe-1460-4c6e-b341-8328283fecdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers 'C:\\Users\\abhin\\AppData\\Local\\Temp\\pip-req-build-dyg1fzah'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to c:\\users\\abhin\\appdata\\local\\temp\\pip-req-build-dyg1fzah\n",
      "  Resolved https://github.com/huggingface/transformers to commit 13493215abceafc1653af88b045120014fb4c1fc\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers==4.47.0.dev0) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0.dev0) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers==4.47.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers==4.47.0.dev0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers==4.47.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers==4.47.0.dev0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers==4.47.0.dev0) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pzM1_ykHaFur"
   },
   "outputs": [],
   "source": [
    "# Importing stock libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NLxxwd1scQNv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "PyTorch version: 2.5.1+cu124\n",
      "GPU name: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "CUDA devices: 1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "\n",
    "# Check CUDA availability\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "print(\"CUDA devices:\", torch.cuda.device_count())\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1u7KONODs_81"
   },
   "source": [
    "<a id='section02'></a>\n",
    "### Preparing the Dataset for Data Processing: Class\n",
    "\n",
    "Starting with the creation of a Dataset class, which defines how the text is pre-processed before feeding it to the neural network. This dataset will be utilized by the Dataloader method, which loads the data in batches for efficient training and processing in the neural network. Both Dataloader and Dataset will be implemented inside the `main()` function. In PyTorch, Dataset and Dataloader constructs are essential for defining data preprocessing and controlling its flow into the neural network. For more details, refer to the [PyTorch Dataset and Dataloader documentation](https://pytorch.org/docs/stable/data.html).\n",
    "\n",
    "#### *CustomDataset* Class\n",
    "- The *CustomDataset* class accepts a DataFrame as input and generates tokenized output compatible with the **T5** model for training.\n",
    "- **T5** tokenizer is used to tokenize data in the `text` and `ctext` columns of the DataFrame.\n",
    "- The tokenizer’s `batch_encode_plus` method performs tokenization, producing `source_id` and `source_mask` from the main text, and `target_id` and `target_mask` from the summary text.\n",
    "- For more on this tokenizer, refer to the [T5 tokenizer documentation](https://huggingface.co/transformers/model_doc/t5.html#t5tokenizer).\n",
    "- The *CustomDataset* class generates two datasets: one for training and one for validation.\n",
    "  - *Training Dataset*: Comprising 80% of the original data, used for fine-tuning the model.\n",
    "  - *Validation Dataset*: Used to evaluate model performance on data unseen during training.\n",
    "\n",
    "#### Dataloader: Called Inside the `main()`\n",
    "- The Dataloader is responsible for creating training and validation dataloaders, which efficiently load data to the neural network in a controlled manner.\n",
    "- Not all data can be loaded into memory at once, so Dataloader parameters like `batch_size` and `max_len` control the volume of data fed to the network.\n",
    "- Training and Validation dataloaders are utilized in their respective phases in the workflow to manage memory and facilitate efficient processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "932p8NhxeNw4"
   },
   "outputs": [],
   "source": [
    "# Creating a custom dataset for reading the dataframe and loading it into the dataloader\n",
    "# to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer  # Initialize the tokenizer\n",
    "        self.data = dataframe  # Store the dataframe\n",
    "        self.source_len = source_len  # Set the maximum length for the source text\n",
    "        self.summ_len = summ_len  # Set the maximum length for the summary text\n",
    "        self.text = self.data.text  # Extract the text column from the dataframe\n",
    "        self.ctext = self.data.ctext  # Extract the ctext (context) column from the dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)  # Return the number of samples in the dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])  # Get the context text at the specified index\n",
    "        ctext = ' '.join(ctext.split())  # Clean the context text by removing extra spaces\n",
    "\n",
    "        text = str(self.text[index])  # Get the text at the specified index\n",
    "        text = ' '.join(text.split())  # Clean the text by removing extra spaces\n",
    "\n",
    "        # Tokenize and encode the context text\n",
    "        source = self.tokenizer.batch_encode_plus(\n",
    "            [ctext], max_length=self.source_len, pad_to_max_length=True, return_tensors='pt'\n",
    "        )\n",
    "        # Tokenize and encode the text\n",
    "        target = self.tokenizer.batch_encode_plus(\n",
    "            [text], max_length=self.summ_len, pad_to_max_length=True, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Extract input IDs and attention masks for the source and target texts\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        # Return a dictionary containing the encoded inputs and masks\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long),  # Source input IDs\n",
    "            'source_mask': source_mask.to(dtype=torch.long),  # Source attention mask\n",
    "            'target_ids': target_ids.to(dtype=torch.long),  # Target input IDs\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)  # Target input IDs (for labels)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8g9lYCles_82"
   },
   "source": [
    "<a id='section03'></a>\n",
    "### Fine-Tuning the Model: Function\n",
    "\n",
    "Defining a training function to fine-tune the model on the training dataset created earlier, iterating over the data for a specified number of epochs. An epoch represents a complete pass of the dataset through the network.\n",
    "\n",
    "This function is called within `main()`.\n",
    "\n",
    "The fine-tuning process in this function involves the following steps:\n",
    "- The epoch count, tokenizer, model, device, training dataloader, and optimizer are passed to the `train()` function when called from `main()`.\n",
    "- The dataloader feeds data to the model in batches as defined by the batch size.\n",
    "- `language_model_labels` are generated from the `target_ids`, and `source_id` and `attention_mask` are extracted.\n",
    "- The model’s output provides a loss value for the forward pass.\n",
    "- This loss value is then used to optimize the neural network weights.\n",
    "- Every 500 steps, the loss value is printed to the console for quick reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SaPAR7TWmxoM"
   },
   "outputs": [],
   "source": [
    "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
    "# The model is put into train mode and then we enumerate over the training loader and pass the data to the defined network\n",
    "\n",
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for _, data in enumerate(loader, 0):\n",
    "        # Move the target IDs to the specified device and set the data type to long\n",
    "        y = data['target_ids'].to(device, dtype=torch.long)\n",
    "        # Prepare the decoder input IDs by removing the last token from each target sequence\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        # Prepare the labels by removing the first token from each target sequence\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        # Replace padding token IDs in the labels with -100 to ignore them in the loss calculation\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        # Move the source IDs and attention masks to the specified device and set the data type to long\n",
    "        ids = data['source_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype=torch.long)\n",
    "\n",
    "        # Forward pass: compute the model output\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "        loss = outputs[0]  # The first element of the output is the loss\n",
    "\n",
    "        # Print the loss every 500 iterations\n",
    "        if _ % 500 == 0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "\n",
    "        optimizer.zero_grad()  # Clear the gradients of all optimized tensors\n",
    "        loss.backward()  # Backward pass: compute the gradients\n",
    "        optimizer.step()  # Update the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7y3nH4gs_83"
   },
   "source": [
    "<a id='section04'></a>\n",
    "### Validating the Model Performance: Function\n",
    "\n",
    "During the validation stage we pass the unseen data(Testing Dataset), trained model, tokenizer and device details to the function to perform the validation run. This step generates new summary for dataset that it has not seen during the training session. \n",
    "\n",
    "This function is called in the `main()`\n",
    "\n",
    "This unseen data is the 20% of `news_summary.csv` which was seperated during the Dataset creation stage. \n",
    "During the validation stage the weights of the model are not updated. We use the generate method for generating new text for the summary. \n",
    "\n",
    "It depends on the `Beam-Search coding` method developed for sequence generation for models with LM head. \n",
    "\n",
    "The generated text and originally summary are decoded from tokens to text and returned to the `main()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j9TNdHlQ0CLz"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []  # Initialize a list to store predictions\n",
    "    actuals = []  # Initialize a list to store actual target sequences\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype=torch.long)  # Move target IDs to the specified device\n",
    "            ids = data['source_ids'].to(device, dtype=torch.long)  # Move source IDs to the specified device\n",
    "            mask = data['source_mask'].to(device, dtype=torch.long)  # Move source attention masks to the specified device\n",
    "\n",
    "            # Generate predictions using the model\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=ids,\n",
    "                attention_mask=mask,\n",
    "                max_length=150,  # Set the maximum length for generated sequences\n",
    "                num_beams=2,  # Use beam search with 2 beams\n",
    "                repetition_penalty=2.5,  # Set the repetition penalty\n",
    "                length_penalty=1.0,  # Set the length penalty\n",
    "                early_stopping=True  # Enable early stopping\n",
    "            )\n",
    "\n",
    "            # Decode the generated IDs to text\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            # Decode the target IDs to text\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in y]\n",
    "\n",
    "            # Print progress every 100 iterations\n",
    "            if _ % 100 == 0:\n",
    "                print(f'Completed {_}')\n",
    "\n",
    "            # Extend the predictions and actuals lists with the current batch\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    \n",
    "    return predictions, actuals  # Return the predictions and actual target sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WX56MJHAs_84"
   },
   "source": [
    "<a id='section05'></a>\n",
    "### Main Function\n",
    "\n",
    "The `main()` as the name suggests is the central location to execute all the functions/flows created above in the notebook. The following steps are executed in the `main()`:\n",
    "\n",
    "\n",
    "<a id='section502'></a>\n",
    "#### Importing and Pre-Processing the domain data\n",
    "\n",
    "We will be working with the data and preparing it for fine tuning purposes. \n",
    "*Assuming that the `news_summary.csv` is already downloaded in your `data` folder*\n",
    "\n",
    "* The file is imported as a dataframe and give it the headers as per the documentation.\n",
    "* Cleaning the file to remove the unwanted columns.\n",
    "* A new string is added to the main article column `summarize: ` prior to the actual article. This is done because **T5** had similar formatting for the summarization dataset. \n",
    "* The final Dataframe will be something like this:\n",
    "\n",
    "|text|ctext|\n",
    "|--|--|\n",
    "|summary-1|summarize: article 1|\n",
    "|summary-2|summarize: article 2|\n",
    "|summary-3|summarize: article 3|\n",
    "\n",
    "* Top 5 rows of the dataframe are printed on the console.\n",
    "\n",
    "<a id='section503'></a>\n",
    "#### Creation of Dataset and Dataloader\n",
    "\n",
    "* The updated dataframe is divided into 80-20 ratio for test and validation. \n",
    "* Both the data-frames are passed to the `CustomerDataset` class for tokenization of the new articles and their summaries.\n",
    "* The tokenization is done using the length parameters passed to the class.\n",
    "* Train and Validation parameters are defined and passed to the `pytorch Dataloader contstruct` to create `train` and `validation` data loaders.\n",
    "* These dataloaders will be passed to `train()` and `validate()` respectively for training and validation action.\n",
    "* The shape of datasets is printed in the console.\n",
    "\n",
    "\n",
    "<a id='section504'></a>\n",
    "#### Neural Network and Optimizer\n",
    "\n",
    "* In this stage we define the model and optimizer that will be used for training and to update the weights of the network. \n",
    "* We are using the `t5-base` transformer model for our project. You can read about the `T5 model` and its features above. \n",
    "* We use the `T5ForConditionalGeneration.from_pretrained(\"t5-base\")` commad to define our model. The `T5ForConditionalGeneration` adds a Language Model head to our `T5 model`. The Language Model head allows us to generate text based on the training of `T5 model`.\n",
    "* We are using the `Adam` optimizer for our project. This has been a standard and is something that can be changed updated to see how different optimizer perform with different learning rates. \n",
    "* There is also a scope for doing more with Optimizer such a decay, momentum to dynamically update the Learning rate and other parameters.\n",
    "\n",
    "\n",
    "<a id='section505'></a>\n",
    "#### Training Model\n",
    "\n",
    "* We call the `train()` with all the necessary parameters.\n",
    "* Loss at every 500th step is printed on the console.\n",
    "\n",
    "\n",
    "<a id='section506'></a>\n",
    "#### Validation and generation of Summary\n",
    "\n",
    "* After the training is completed, the validation step is initiated.\n",
    "* As defined in the validation function, the model weights are not updated. We use the fine tuned model to generate new summaries based on the article text.\n",
    "* An output is printed on the console giving a count of how many steps are complete after every 100th step. \n",
    "* The original summary and generated summary are converted into a list and returned to the main function. \n",
    "* Both the lists are used to create the final dataframe with 2 columns **Generated Summary** and **Actual Summary**\n",
    "* The dataframe is saved as a csv file in the local drive.\n",
    "* A qualitative analysis can be done with the Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  The Administration of Union Territory Daman an...   \n",
      "1  Malaika Arora slammed an Instagram user who tr...   \n",
      "2  The Indira Gandhi Institute of Medical Science...   \n",
      "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
      "4  Hotels in Maharashtra will train their staff t...   \n",
      "\n",
      "                                               ctext  \n",
      "0  summarize: The Daman and Diu administration on...  \n",
      "1  summarize: From her special numbers to TV?appe...  \n",
      "2  summarize: The Indira Gandhi Institute of Medi...  \n",
      "3  summarize: Lashkar-e-Taiba's Kashmir commander...  \n",
      "4  summarize: Hotels in Mumbai and other Indian c...  \n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 2    # input batch size for training\n",
    "VALID_BATCH_SIZE = 2    # input batch size for testing\n",
    "TRAIN_EPOCHS = 2        # number of epochs to train\n",
    "VAL_EPOCHS = 1 \n",
    "LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
    "SEED = 42               \n",
    "MAX_LEN = 512\n",
    "SUMMARY_LEN = 150 \n",
    "\n",
    "# Set random seeds and deterministic pytorch for reproducibility\n",
    "torch.manual_seed(SEED) # pytorch random seed\n",
    "np.random.seed(SEED) # numpy random seed\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# tokenzier for encoding the text\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Importing and Pre-Processing the domain data\n",
    "# Selecting the needed columns only. \n",
    "# Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
    "df = pd.read_csv('../data/news_summary.zip',encoding='latin-1')\n",
    "df = df[['text','ctext']]\n",
    "df.ctext = 'summarize: ' + df.ctext\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (4514, 2)\n",
      "TRAIN Dataset: (3611, 2)\n",
      "TEST Dataset: (903, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creation of Dataset and Dataloader\n",
    "\n",
    "# Defining the train size. So 80% of the data will be used for training and the rest will be used for validation.\n",
    "train_size = 0.8\n",
    "train_dataset = df.sample(frac=train_size, random_state=SEED).reset_index(drop=True)  # Sample 80% of the data for training\n",
    "val_dataset = df.drop(train_dataset.index).reset_index(drop=True)  # Use the remaining 20% for validation\n",
    "\n",
    "# Print the shapes of the full dataset, training dataset, and validation dataset\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(val_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating the Training and Validation dataset for further creation of Dataloader\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)  # Create a custom dataset for training\n",
    "val_set = CustomDataset(val_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)  # Create a custom dataset for validation\n",
    "\n",
    "# Defining the parameters for creation of dataloaders\n",
    "train_params = {\n",
    "    'batch_size': TRAIN_BATCH_SIZE,  # Set the batch size for training\n",
    "    'shuffle': True,  # Shuffle the data for training\n",
    "    'num_workers': 0  # Number of worker threads for loading data\n",
    "}\n",
    "\n",
    "val_params = {\n",
    "    'batch_size': VALID_BATCH_SIZE,  # Set the batch size for validation\n",
    "    'shuffle': False,  # Do not shuffle the data for validation\n",
    "    'num_workers': 0  # Number of worker threads for loading data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model already exists. Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\AppData\\Local\\Temp\\ipykernel_14808\\3530201119.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "# Define the path to save the model\n",
    "MODEL_PATH = \"t5_fine_tuned_model.pth\"\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check if the model already exists\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"Trained model already exists. Loading the model...\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "else:\n",
    "    print(\"No trained model found. Starting training...\")\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)  # Create a DataLoader for the training set\n",
    "    val_loader = DataLoader(val_set, **val_params)  # Create a DataLoader for the validation set\n",
    "\n",
    "    # Assuming you have already defined your model, tokenizer, training_loader, etc.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Training loop\n",
    "    print('Initiating Fine-Tuning for the model on our dataset')\n",
    "\n",
    "    for epoch in range(TRAIN_EPOCHS):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "\n",
    "    # Save the model after training\n",
    "    torch.save(model.state_dict(), MODEL_PATH)\n",
    "    print(f\"Model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now generating summaries on our fine-tuned model for the validation dataset and saving it in a dataframe\n",
      "Completed 0\n",
      "Completed 100\n",
      "Completed 200\n",
      "Completed 300\n",
      "Completed 400\n",
      "Output Files generated for review\n"
     ]
    }
   ],
   "source": [
    "# Validation loop and saving the resulting file with predictions and actuals in a dataframe.\n",
    "# Saving the dataframe as predictions.csv\n",
    "\n",
    "print('Now generating summaries on our fine-tuned model for the validation dataset and saving it in a dataframe')\n",
    "\n",
    "for epoch in range(VAL_EPOCHS):\n",
    "    # Call the validate function to generate predictions and actual summaries for the validation dataset\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "    \n",
    "    # Create a DataFrame to store the generated and actual summaries\n",
    "    final_df = pd.DataFrame({'Generated Text': predictions, 'Actual Text': actuals})\n",
    "    \n",
    "    # Save the DataFrame to a CSV file named predictions.csv\n",
    "    final_df.to_csv('predictions.csv')\n",
    "    # final_df.to_csv('code\\evaluation\\predictions.csv')\n",
    "    \n",
    "    # Print a message indicating that the output files have been generated\n",
    "    print('Output Files generated for review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcwSsnq9s_85"
   },
   "source": [
    "<a id='section06'></a>\n",
    "### Examples of the Summary Generated from the model\n",
    "\n",
    "##### Example 1\n",
    "\n",
    "**Original Text**\n",
    "New Delhi, Apr 25 (PTI) Union minister Vijay Goel today batted for the unification of the three municipal corporations in the national capital saying a discussion over the issue was pertinent. The BJP leader, who was confident of a good show by his party in the MCD polls, the results of which will be declared tomorrow, said the civic bodies needed to be \"revamped\" in order to deliver the services to the people more effectively. The first thing needed was a discussion on the unification of the three municipal corporations and there should also be an end to the practice of sending Delhi government officials to serve in the civic bodies, said the Union Minister of State (Independent Charge) for Youth Affairs and Sports. \"Barring one, the two other civic bodies have been incurring losses. It would be more fruitful and efficient if all the three were merged,\" he said, referring to the north, south and east Delhi municipal corporations. The erstwhile Municipal Corporation of Delhi (MCD) was trifurcated into NDMC, SDMC and EDMC by the then Sheila Dikshit-led Delhi government in 2012. Goel predicted a \"thumping\" victory for the BJP in the MCD polls. He said the newly-elected BJP councillors will be trained on the functioning of the civic bodies and dealing with the bureaucracy. \n",
    "\n",
    "\n",
    "**Original Summary**\n",
    "Union Minister Vijay Goel has favoured unification of three MCDs ? North, South and East ? in order to deliver the services more effectively. \"Barring one, the two other civic bodies have been incurring losses. It would be more fruitful and efficient if all the three were merged,\" he said. MCD was trifurcated into EDMC, NDMC and SDMC in 2012.\n",
    "\n",
    "**Generated Summary**\n",
    "BJP leader Vijay Goel on Saturday batted for the unification of three municipal corporations in the national capital saying a discussion over this was pertinent. \"Barring one, two other civic bodies have been incurring losses,\" said Goels. The erstwhile Municipal Corporations of Delhi (MCD) were trifurcated into NDMC and SDMC by the then Sheilha Dikshi-led government in 2012. Notably, the MCD poll results will be declared tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YfvxeW4s_85"
   },
   "source": [
    "##### Example 2\n",
    "\n",
    "**Original Text**\n",
    "After much wait, the first UDAN flight took off from Shimla today after being flagged off by Prime Minister Narendra Modi.The flight will be operated by Alliance Air, the regional arm of Air India. PM Narendra Modi handed over boarding passes to some of passengers travelling via the first UDAN flight at the Shimla airport.Tomorrow PM @narendramodi will flag off the first UDAN flight under the Regional Connectivity Scheme, on Shimla-Delhi sector.Air India yesterday opened bookings for the first launch flight from Shimla to Delhi with all inclusive fares starting at Rs2,036.THE GREAT 'UDAN'The UDAN (Ude Desh ka Aam Naagrik) scheme seeks to make flying more affordable for the common people, holding a plan to connect over 45 unserved and under-served airports.Under UDAN, 50 per cent of the seats on each flight would have a cap of Rs 2,500 per seat/hour. The government has also extended subsidy in the form of viability gap funding to the operators flying on these routes.The scheme was launched to \"make air travel accessible to citizens in regionally important cities,\" and has been described as \"a first-of-its-kind scheme globally to stimulate regional connectivity through a market-based mechanism.\" Report have it the first flight today will not be flying at full capacity on its 70-seater ATR airplane because of payload restrictions related to the short Shimla airfield.|| Read more ||Udan scheme: Now you can fly to these 43 cities, see the full list hereUDAN scheme to fly hour-long flights capped at Rs 2,500 to smaller cities \n",
    "\n",
    "\n",
    "**Original Summary**\n",
    "PM Narendra Modi on Thursday launched Ude Desh ka Aam Nagrik (UDAN) scheme for regional flight connectivity by flagging off the inaugural flight from Shimla to Delhi. Under UDAN, government will connect small towns by air with 50% plane seats' fare capped at?2,500 for a one-hour journey of 500 kilometres. UDAN will connect over 45 unserved and under-served airports.\n",
    "\n",
    "**Generated Summary**\n",
    "UDAN (Ude Desh Ka Aam Naagrik) scheme, launched to make air travel accessible in regionally important cities under the Regional Connectivity Scheme, took off from Shimla on Tuesday. The first flight will be operated by Alliance Air, which is the regional arm of India's Air India. Under the scheme, 50% seats would have?2,500 per seat/hour and 50% of the seats would have capped at this rate. It was also extended subsidy in form-based funding for operators flying these routes as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_H63Zdts_85"
   },
   "source": [
    "##### Example 3\n",
    "\n",
    "**Original Text**\n",
    "New Delhi, Apr 25 (PTI) The Income Tax department has issued a Rs 24,646 crore tax demand notice to Sahara Groups Aamby Valley Limited (AVL) after conducting a special audit of the company. The department, as part of a special investigation and audit into the account books of AVL, found that an income of over Rs 48,000 crore for a particular assessment year was allegedly not reflected in the record books of the firm and hence it raised a fresh tax demand and penalty amount on it. A Sahara Group spokesperson confirmed the development to PTI. \"Yes, the Income Tax Department has raised Rs 48,085.79 crores to the income of the Aamby Valley Limited with a total demand of income tax of Rs 24,646.96 crores on the Aamby Valley Limited,\" the spokesperson said in a brief statement. Officials said the notice was issued by the taxman in January this year after the special audit of AVLs income for the Assessment Year 2012-13 found that the parent firm had allegedly floated a clutch of Special Purpose Vehicles whose incomes were later accounted on the account of AVL as they were merged with the former in due course of time. The AVL, in its income return filed for AY 2012-13, had reflected a loss of few crores but the special I-T audit brought up the added income, a senior official said. The Supreme Court, last week, had asked the Bombay High Courts official liquidator to sell the Rs 34,000 crore worth of properties of Aamby Valley owned by the Sahara Group and directed its chief Subrata Roy to personally appear before it on April 28.  \n",
    "\n",
    "\n",
    "**Original Summary**\n",
    "The Income Tax Department has issued a ?24,646 crore tax demand notice to Sahara Group's Aamby Valley Limited. The department's audit found that an income of over ?48,000 crore for the assessment year 2012-13 was not reflected in the record books of the firm. A week ago, the SC ordered Bombay HC to auction Sahara's Aamby Valley worth ?34,000 crore.\n",
    "\n",
    "**Generated Summary**\n",
    "the Income Tax department has issued a?24,646 crore tax demand notice to Sahara Groups Aamby Valley Limited (AVL) after conducting an audit of the company. The notice was issued in January this year after the special audit found that the parent firm had floated Special Purpose Vehicle income for the Assessment Year 2012-13 and later accounted on its account as they were merged with the former. \"Yes...the Income Tax Department raised Rs48,085.79 crores to the income,\" he added earlier said at the notice."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "transformers-summarization-t5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
